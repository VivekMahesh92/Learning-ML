{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "ed7cbdb76f029e40b2938ce9386b50261706ee7945092ce446037e65149312dc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Delving deeper into ml methods, better metrics are needed to find the best approach to a particular task. Fine tuning the ML models comes into play in this section\n",
    "\n",
    "In this book methods to improve already used ML methods and models are considered"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules for the tasks at hand\n",
    "# datasets also imported rather than using any external files (like CVS, SPSS etc.)\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "Confusion matrix\n",
    "\n",
    "Its a table used to describe performance of a classification model (or classifier) on a set of test data for which the values are known"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# adding the dataset to be used at the start\n",
    "cancer = datasets.load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 77   3]\n [  4 144]]\n"
     ]
    }
   ],
   "source": [
    "# predict the values using k-NN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# confusion matrix calculation \n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96        80\n           1       0.98      0.97      0.98       148\n\n    accuracy                           0.97       228\n   macro avg       0.97      0.97      0.97       228\nweighted avg       0.97      0.97      0.97       228\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9692982456140351"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# accuracy metric or score for the dataset\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "Hyperparameter tuning\n",
    "\n",
    "Method of selecting the parameter used in the models like k in kNN and alpha in regression\n",
    "\n",
    "one method is grid search cross validation is done to get an optimised value for the k in the below case for kNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameter: {'n_neighbors': 13}\nBest score: 0.9332401800962584\n"
     ]
    }
   ],
   "source": [
    "# import the required module values\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameter grid to varry the k value over\n",
    "param_grid = {\"n_neighbors\" : np.arange(1,50)}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = 5)\n",
    "knn_cv.fit(X,y)\n",
    "\n",
    "print(\"Best parameter: {}\".format(knn_cv.best_params_))\n",
    "print(\"Best score: {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "source": [
    "Randomized Search CV is used when the hyperparameter space is large which when used with Grid Search CV can lead to being computationally expensive.\n",
    "\n",
    "For this DecisionTree is used as the classifer, here the number of params are also more than kNN and regression "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Programming\\Python\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 3}\n",
      "Best Score: 0.020352400408580187\n"
     ]
    }
   ],
   "source": [
    "# import the randomized func from scipy\n",
    "from scipy.stats import randint\n",
    "\n",
    "# import the dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "#import decisiontree and randomized search cv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#parameters for decision tree which can be changed to tune the classfier\n",
    "param_dist = {\"max_depth\" : [3, None],\n",
    "                \"max_features\" : randint(1,9),\n",
    "                \"min_samples_leaf\" : randint(1,9),\n",
    "                \"criterion\" : [\"gini\", \"entropy\"]}\n",
    "\n",
    "# initialize the decision tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# applying the tuning\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv = 5)\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "#print the output which is the params used as well as the score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best Score: {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}